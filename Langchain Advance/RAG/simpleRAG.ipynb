{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915f2660",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf520fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ae16c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'exmples.txt'}, page_content='This is a small sample document for testing RAG pipelines.\\nIt contains a few sentences about LangChain and retrieval.\\nYou can add more lines to improve chunking and recall.\\nRAG systems fetch relevant text before generating answers.\\n')]\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"exmples.txt\")\n",
    "text_docs = loader.load()\n",
    "print(text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbcf2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ecce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = \"arcee-ai/trinity-large-preview:free\",\n",
    "    temperature = 0.9,\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8000\",\n",
    "        \"X-Title\": \"RAG with Langchain\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c94aab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders  import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "## Load CHUNK AND INDEX:\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://www.geeksforgeeks.org/artificial-intelligence/what-is-artificial-intelligence-ai/\",\n",
    "    bs_kwargs={\"parse_only\": bs4.SoupStrainer(\n",
    "        class_=[\"ArticleHeader_article-title__futDC\", \"MainArticleContent_articleMainContentCss__b_1_R article--viewer_content\", \"html-chunk\"]\n",
    "    )}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "609a9cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Artificial Intelligence (AI)Artificial Intelligence (AI) is a technology that enables machines and computers to perform tasks that typically require human intelligence. It helps systems learn from data, recognize patterns and make decisions to solve complex problems. It is used in healthcare, finance, e-commerce and transportation offering personalized recommendations and enabling self-driving cars.Core Concepts of AIAI is based on core concepts and technologies that enable machines to learn, reason and make decisions on their own. Let's see some of the concepts:1. Machine Learning (ML)Machine Learning is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed to perform a task, a machine learning model uses algorithms to identify patterns within data and improve its performance over time without human intervention.2. Generative AIGenerative AI is designed to create new content whether it's text, images, music or video. Unlike traditional AI which typically focuses on analyzing and classifying data, it goes a step further by using patterns it has learned from large datasets to generate new original outputs. It \"creates\" rather than just \"recognizes.\"3. Natural Language Processing (NLP)Natural Language Processing (NLP) allows machines to understand and interact with human language in a way that feels natural. It enables speech recognition systems like Siri or Alexa to interpret what we say and respond accordingly. It combines linguistics and computer science to help computers process, understand and generate human language allowing for tasks like language translation, sentiment analysis and real-time conversation.4. Expert SystemsExpert Systems are designed to simulate the decision-making ability of human experts. These systems use a set of predefined \"if-then\" rules and knowledge from specialists in specific fields to make informed decisions similar to how a medical professional would diagnose a disease. They are useful in areas where expert knowledge is important but not always easily accessible. Working of Artificial IntelligenceAI works by simulating intelligent behavior to perform tasks autonomously. The process involves several steps that help machines learn, make decisions and improve over time:Data Collection: AI systems rely on large sets of data which could include images, text or sensor readings. For example, teaching an AI to recognize cats, we collect a dataset of labeled cat images.Processing and Learning: It uses algorithms to analyze data and identify patterns. For example, it learns to recognize key features like a cat’s shape, ears or whiskers helping it understand the data.Model Training: The AI model is trained using the data, adjusting its internal settings to improve its predictions. With more data, the model becomes more accurate and better at recognizing new examples like unseen images of cats.Decision Making: Once trained, it can use what it has learned to make decisions. For example, it can find whether a new image contains a cat based on the patterns it learned during training.Feedback and Improvement: It can improve through feedback, especially in methods like reinforcement learning. In this case, the AI receives rewards or penalties, refining its ability to make better decisions over time.Types of Artificial IntelligenceAI can be classified into two main categories based on its capabilities and functionalities.1. Based on Capabilities:Narrow AI (Weak AI): This type of AI is designed to perform a specific task or a narrow set of tasks such as voice assistants or recommendation systems. It is good in one area like recommending products or recognizing speech but lacks general intelligence.General AI (Strong AI): It is a theoretical concept where AI can perform any intellectual task that a human can do. It shows human-like reasoning and understanding across multiple domains, making it capable of tackling a variety of tasks.Superintelligent AI: It is a hypothetical form of AI that would surpass human intelligence in all areas. It would be capable of performing tasks more efficiently and effectively than humans.2. Based on Functionalities:Reactive Machines: These AI systems only react to specific tasks without storing past experiences. They don’t learn from previous actions but respond in a set way. For example is a chess-playing AI that evaluates the board and makes a move based on the current position.Limited Memory: These AI systems can use past data to improve future decisions. Self-driving cars are a good example, as they use data from previous trips to navigate roads and avoid obstacles.Theory of Mind: The theory of mind is a theoretical type of AI that would be able to understand emotions, beliefs, intentions and other mental states. This would allow the AI to interact with humans in a more natural and empathetic manner.Self-Aware AI: It is a hypothetical form of AI that possesses consciousness and self-awareness. It would have an understanding of its own existence and could make decisions based on that awareness.AI ModelsAI models are programs that learn from data and make decisions or predictions based on what they've learned. These models help AI perform tasks by recognizing patterns in data similar to how humans learn from experience. Different models use various learning approaches depending on how they are trained. Let's see some of the common types of AI models:1. Supervised Learning ModelsIn Supervised learning, AI is trained on labeled data with clear input-output pairs, helping the system to learn the relationship between them.The model is adjusted during training to reduce the difference between its predictions and the correct outputs.It’s used for tasks like image classification, spam filtering and medical diagnosis where labeled datasets are available.2. Unsupervised Learning ModelsIn Unsupervised Learning models, AI works with unlabeled data and identifies patterns, trends or groupings without direct guidance.It is valuable when exploring hidden structures in complex datasets such as detecting fraud.This method helps in tasks like customer segmentation, data clustering and anomaly detection.3. Reinforcement Learning ModelsIn Reinforcement learning, AI learns by interacting with an environment and receiving feedback in the form of rewards or penalties.Over time, the model optimizes its decision-making process to maximize positive outcomes.It is used in robotics, gaming (e.g AlphaGo) and autonomous systems where actions lead to varying consequences and the AI learns through experience.Advantages of AIAI offers a range of benefits that improve productivity, decision-making and user experience across multiple sectors. Let's see some key advantages:Efficiency and Automation: AI automates repetitive tasks, smoothen workflows and reducing human errors. This helps us save time and concentrate on more strategic and innovative tasks.Improved Decision Making: AI's ability to process and analyze large datasets helps businesses and individuals make informed, data-driven decisions. This is beneficial in sectors like healthcare, finance and retail.Personalization: It helps personalize experiences by analyzing user preferences and customizing recommendations. This enhances user satisfaction, as seen in platforms like Netflix, Amazon and social media feeds.24/7 Availability: Unlike humans, AI can operate continuously without rest, making it ideal for round-the-clock tasks such as customer support, security monitoring and data collection.Data Analysis and Pattern Recognition: It is proficient at analyzing large volumes of data and identifying patterns that may be difficult for humans to recognize. This capability helps in areas like healthcare diagnostics, fraud detection and market analysis.Real-World Applications of AIArtificial Intelligence has many practical applications across various industries and domains including:Healthcare: AI helps in early diagnosis and treatment recommendations by analyzing medical data such as images and patient history, improving preventative care.Retail: It personalizes shopping experiences by recommending products based on user behavior. It also helps optimize inventory management and predict demand, ensuring efficient stock control and better customer satisfaction.Customer Service: AI-powered chatbots handle routine customer inquiries, provide support 24/7 and escalate more complex issues to human agents. This improves efficiency and reduces wait times, enhancing overall customer experience.Manufacturing: It improves production efficiency by predicting machine maintenance needs, preventing downtime and also enhances supply chain management by forecasting demand, optimizing operations and reducing waste.Finance: AI in finance detects fraud, analyzes market data and automates risk management. It also assists in personalized investment advice, helping individuals make smarter financial decisions.Challenges of AIDespite of having various advantages, it have some challenges which need to be resolved:Data Privacy and Security: AI systems require vast amounts of data which can raise concerns about data privacy and protection. Ensuring sensitive information is secure and maintaining user trust is a significant challenge.Bias and Fairness: They can inherit biases from the data they are trained on, leading to unfair or discriminatory outcomes. Addressing these biases is important for ensuring AI systems make impartial decisions.Lack of Transparency: AI models, especially deep learning can often act as \"black boxes\" making it difficult to understand how they make decisions. This lack of transparency can be problematic in areas like healthcare or law enforcement.Job Displacement: It automates tasks traditionally performed by humans, concerns about job losses in certain sectors arise. Ensuring a smooth transition for workers and retraining them for new roles is essential.Ethical Concerns: The use of AI in sensitive areas like surveillance, autonomous weapons and decision-making raises ethical questions. Finding a balance between technological innovation and ethical accountability remains a continuous challenge in AI development.\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc027f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "path = \"AI-for-Education-RAG.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf00379",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e11899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c2ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = recursive_splitter.split_documents(docs)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8435efe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using your own content in LLM’s -\n",
      "Retrieval Augmented Generation\n",
      "(RAG)\n",
      "Gen-AI can help with education in many ways\n",
      "Saves time\n",
      "• AI lesson planning reduces the time teachers spend preparing lessons. \n",
      "• Can automate marking using AI – image recognition or voice technologies to assess students as \n",
      "they read aloud.\n",
      "Improved quality\n",
      "• Adapt high quality resources to your context (languages or images).\n",
      "• Can help teachers clarify concepts they may have forgotten.\n",
      "• Adapt lessons/examples to children’s previous answers.\n",
      "Improved scalability\n",
      "• Access on phones (e.g. chatbot to support teachers) enables wide adoption. \n",
      "• Rapid integration of new national policies, curricula and best practices by automatically updating \n",
      "knowledge bases of LLMs.\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].page_content)\n",
    "print(documents[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f22b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "character_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "character_documents = character_splitter.split_documents(docs)\n",
    "print(len(character_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467231d6",
   "metadata": {},
   "source": [
    "# Embeddings and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d23e4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    task=\"feature-extraction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "494f3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b41c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9484\\188925315.py:15: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()  # writes to disk\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import VoyageEmbeddings\n",
    "import os\n",
    "\n",
    "os.environ[\"VOYAGE_API_KEY\"]  \n",
    "\n",
    "voyage_embeddings = VoyageEmbeddings(\n",
    "    model=\"voyage-2\",         \n",
    "    batch_size=32             \n",
    ")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    voyage_embeddings,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "vectorstore.persist()  # writes to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Retrieval Augmented Generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a899c32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'source': 'AI-for-Education-RAG.pdf', 'page_label': '7', 'moddate': '2024-03-04T11:16:13+00:00', 'total_pages': 18, 'page': 6, 'creator': 'PyPDF', 'creationdate': '2024-03-04T11:16:13+00:00'}, page_content='What is Retrieval Augmented Generation (RAG)?\\n• RAG is an extension of Large Language Models (LLMs)\\n• LLMs are things like GPT4, Gemini, Claude, LLaMA, Mistral, etc.\\n• So, to understand what RAG is, it first helps to recap what an LLM is (and \\nwhat it isn’t)\\n7'),\n",
       " Document(metadata={'creator': 'PyPDF', 'page': 4, 'moddate': '2024-03-04T11:16:13+00:00', 'producer': 'PyPDF', 'page_label': '5', 'total_pages': 18, 'creationdate': '2024-03-04T11:16:13+00:00', 'source': 'AI-for-Education-RAG.pdf'}, page_content='In this series, we will talk through different ways \\nusing core education materials. \\nToday we focus on Retrieval Augmented Generation \\n(RAG)\\n1. Prompt Engineering \\n2. RAG systems\\n3. Fine-tuning \\n4. Rebuilding foundational models.'),\n",
       " Document(metadata={'creator': 'PyPDF', 'page_label': '1', 'producer': 'PyPDF', 'creationdate': '2024-03-04T11:16:13+00:00', 'source': 'AI-for-Education-RAG.pdf', 'total_pages': 18, 'page': 0, 'moddate': '2024-03-04T11:16:13+00:00'}, page_content='Using your own content in LLM’s -\\nRetrieval Augmented Generation\\n(RAG)'),\n",
       " Document(metadata={'creator': 'PyPDF', 'moddate': '2024-03-04T11:16:13+00:00', 'page_label': '15', 'total_pages': 18, 'creationdate': '2024-03-04T11:16:13+00:00', 'producer': 'PyPDF', 'page': 14, 'source': 'AI-for-Education-RAG.pdf'}, page_content='There are many considerations for a RAG model\\nSplit into the two key components: Retrieval and Generation\\nRetrieval: Finding relevant information\\n• It’s like going to a huge library and finding the most relevant books to answer the \\nquestion\\nGeneration: How do we use the retrieved information for response\\n• Like an expert scholar summarises the information in the books you have picked out\\n15')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = vectorstore.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9abecb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is Retrieval Augmented Generation (RAG)?\\n• RAG is an extension of Large Language Models (LLMs)\\n• LLMs are things like GPT4, Gemini, Claude, LLaMA, Mistral, etc.\\n• So, to understand what RAG is, it first helps to recap what an LLM is (and \\nwhat it isn’t)\\n7'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ad94bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this series, we will talk through different ways \\nusing core education materials. \\nToday we focus on Retrieval Augmented Generation \\n(RAG)\\n1. Prompt Engineering \\n2. RAG systems\\n3. Fine-tuning \\n4. Rebuilding foundational models.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc1b846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using your own content in LLM’s -\\nRetrieval Augmented Generation\\n(RAG)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f78d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are many considerations for a RAG model\\nSplit into the two key components: Retrieval and Generation\\nRetrieval: Finding relevant information\\n• It’s like going to a huge library and finding the most relevant books to answer the \\nquestion\\nGeneration: How do we use the retrieved information for response\\n• Like an expert scholar summarises the information in the books you have picked out\\n15'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[3].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2533e1a",
   "metadata": {},
   "source": [
    "# Retriever and Chain In Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26b70d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model = \"arcee-ai/trinity-large-preview:free\",\n",
    "    temperature = 0.9,\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8000\",\n",
    "        \"X-Title\": \"RAG with Langchain\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a43e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Answer the Following Question based on the Provided Context only.\n",
    "    Make sure the answer is satisfactiable.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    Question: {input}                        \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c475d",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6c58edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71e8db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_document = create_stuff_documents_chain(model, prompt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e00392",
   "metadata": {},
   "source": [
    "## Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e3dcdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'VoyageEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001E3B0C84CD0>, search_kwargs={})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ae59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriver with Chain\n",
    "from langchain_classic.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c41b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreival_chain = create_retrieval_chain(retriever, chain_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12e0a3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Retrieval Augmented Generation',\n",
       " 'context': [Document(metadata={'page_label': '7', 'creator': 'PyPDF', 'creationdate': '2024-03-04T11:16:13+00:00', 'page': 6, 'total_pages': 18, 'source': 'AI-for-Education-RAG.pdf', 'moddate': '2024-03-04T11:16:13+00:00', 'producer': 'PyPDF'}, page_content='What is Retrieval Augmented Generation (RAG)?\\n• RAG is an extension of Large Language Models (LLMs)\\n• LLMs are things like GPT4, Gemini, Claude, LLaMA, Mistral, etc.\\n• So, to understand what RAG is, it first helps to recap what an LLM is (and \\nwhat it isn’t)\\n7'),\n",
       "  Document(metadata={'page': 4, 'creator': 'PyPDF', 'page_label': '5', 'total_pages': 18, 'source': 'AI-for-Education-RAG.pdf', 'moddate': '2024-03-04T11:16:13+00:00', 'producer': 'PyPDF', 'creationdate': '2024-03-04T11:16:13+00:00'}, page_content='In this series, we will talk through different ways \\nusing core education materials. \\nToday we focus on Retrieval Augmented Generation \\n(RAG)\\n1. Prompt Engineering \\n2. RAG systems\\n3. Fine-tuning \\n4. Rebuilding foundational models.'),\n",
       "  Document(metadata={'producer': 'PyPDF', 'creationdate': '2024-03-04T11:16:13+00:00', 'total_pages': 18, 'page_label': '1', 'page': 0, 'source': 'AI-for-Education-RAG.pdf', 'creator': 'PyPDF', 'moddate': '2024-03-04T11:16:13+00:00'}, page_content='Using your own content in LLM’s -\\nRetrieval Augmented Generation\\n(RAG)'),\n",
       "  Document(metadata={'source': 'AI-for-Education-RAG.pdf', 'page': 14, 'page_label': '15', 'creator': 'PyPDF', 'moddate': '2024-03-04T11:16:13+00:00', 'producer': 'PyPDF', 'creationdate': '2024-03-04T11:16:13+00:00', 'total_pages': 18}, page_content='There are many considerations for a RAG model\\nSplit into the two key components: Retrieval and Generation\\nRetrieval: Finding relevant information\\n• It’s like going to a huge library and finding the most relevant books to answer the \\nquestion\\nGeneration: How do we use the retrieved information for response\\n• Like an expert scholar summarises the information in the books you have picked out\\n15')],\n",
       " 'answer': 'Retrieval Augmented Generation (RAG) is an extension of Large Language Models (LLMs) that combines two key components: Retrieval and Generation. The Retrieval component involves finding relevant information from a large dataset, similar to searching for the most relevant books in a library to answer a question. The Generation component involves using the retrieved information to create a coherent and accurate response, much like an expert scholar summarizing the information from the selected books. RAG enhances the capabilities of LLMs by incorporating external data to improve the quality and relevance of the generated responses.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retreival_chain.invoke({\"input\": \"What is Retrieval Augmented Generation\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03362be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Retrieval Augmented Generation (RAG) is an extension of Large Language Models (LLMs) that combines two key components: Retrieval and Generation. The Retrieval component involves finding relevant information from a large dataset, similar to searching for the most relevant books in a library to answer a question. The Generation component involves using the retrieved information to create a coherent and accurate response, much like an expert scholar summarizing the information from the selected books. RAG enhances the capabilities of LLMs by incorporating external data to improve the quality and relevance of the generated responses.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
