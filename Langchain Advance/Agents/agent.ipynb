{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31126672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd5d1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k=2, doc_content_chars_max=300)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5aaf8a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import VoyageEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b484b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.embeddings.voyageai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised SSLError: HTTPSConnectionPool(host='api.voyageai.com', port=443): Max retries exceeded with url: /v1/embeddings (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1032)'))).\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.langchain.com/oss/python/langchain/agents\")\n",
    "Website_docs = loader.load()\n",
    "website_Splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(Website_docs)\n",
    "os.environ[\"VOYAGE_API_KEY\"]  \n",
    "\n",
    "voyage_embeddings = VoyageEmbeddings(\n",
    "    model=\"voyage-2\",         \n",
    "    batch_size=32             \n",
    ")\n",
    "vectorstore = FAISS.from_documents(\n",
    "    website_Splitter,\n",
    "    voyage_embeddings,\n",
    ")\n",
    "vectorstore.save_local(\"faiss_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "467a085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a35382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain_agents'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "retriever = vectorstore_retriever\n",
    "\n",
    "def summarize_docs(query: str) -> str:\n",
    "    docs = retriever.invoke(query)\n",
    "    if not docs:\n",
    "        return \"No relevant context found.\"\n",
    "    chunks = [f\"Source {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs[:4])]\n",
    "    return \"\\n\\n\".join(chunks)\n",
    "\n",
    "langchain_agents_tool = Tool(\n",
    "    name=\"Langchain_agents\",\n",
    "    description=\"Answer questions about LangChain agents docs.\",\n",
    "    func=summarize_docs,\n",
    ")\n",
    "langchain_agents_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f986f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A website where all the research papers are published is arxiv. We can use arxiv API to fetch the research papers and create a tool for it. \n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun \n",
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k=2, doc_content_chars_max=300)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f7818aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool, langchain_agents_tool, arxiv_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83fa1bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\HP\\\\.conda\\\\envs\\\\myenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=300)),\n",
       " Tool(name='Langchain_agents', description='Answer questions about LangChain agents docs.', func=<function summarize_docs at 0x0000018EEC82D120>),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=300))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e537f49",
   "metadata": {},
   "source": [
    "# AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd8b3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model = \"arcee-ai/trinity-large-preview:free\",\n",
    "    temperature = 0.9,\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8000\",\n",
    "        \"X-Title\": \"RAG with Langchain\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09f34c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant who answers questions with the help of tools. \"\n",
    "     \"You have access to the following tools:\\n{tools}\\n\"\n",
    "     \"If you still don't know the answer after using the tools, say \\\"I don't know\\\".\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=(\n",
    "        \"You are a helpful assistant who answers questions with the help of tools. \"\n",
    "        \"You have access to the following tools:\\n{tools}\\n\"\n",
    "        \"If you still don't know the answer after using the tools, say \\\"I don't know\\\".\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74d17e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='when was attention all you need paper realeased and what was that about ', additional_kwargs={}, response_metadata={}, id='eda98ed1-a4ca-4b10-aa88-a65e2f0577eb'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 353, 'total_tokens': 377, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'arcee-ai/trinity-large-preview:free', 'system_fingerprint': None, 'id': 'gen-1770578825-5O2oVxnntpoUXkeuQKjM', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c3eb8-b5e8-7a41-9b9a-d216a3238962-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Attention Is All You Need paper'}, 'id': 'call-bcf1be3f-e7d3-4c9c-83a7-ace15beb1ad3', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 353, 'output_tokens': 24, 'total_tokens': 377, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Page: Attention Is All You Need\\nSummary: \"Attention Is All You Need\" is a 2017 research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahda', name='wikipedia', id='35fb3fe8-4db8-4d7f-8fa9-a09e36a299a8', tool_call_id='call-bcf1be3f-e7d3-4c9c-83a7-ace15beb1ad3'), AIMessage(content='The paper \"Attention Is All You Need\" was released in 2017. It was authored by eight scientists working at Google and introduced a new deep learning architecture known as the transformer. This architecture is based on the attention mechanism proposed in 2014 by Bahdanau et al.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 450, 'total_tokens': 508, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'arcee-ai/trinity-large-preview:free', 'system_fingerprint': None, 'id': 'gen-1770578851-Kyaff8QO4NIO2RRUFW5Q', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3eb9-2f4d-7ea0-a83e-7f2d0ea2787b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 450, 'output_tokens': 58, 'total_tokens': 508, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "Query = input(\"Enter your Query\")\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": Query}]}\n",
    "result = agent.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27fbcdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper \"Attention Is All You Need\" was released in 2017. It was authored by eight scientists working at Google and introduced a new deep learning architecture known as the transformer. This architecture is based on the attention mechanism proposed in 2014 by Bahdanau et al.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
