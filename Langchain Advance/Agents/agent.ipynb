{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31126672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd5d1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k=2, doc_content_chars_max=300)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5aaf8a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import VoyageEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b484b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.embeddings.voyageai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised SSLError: HTTPSConnectionPool(host='api.voyageai.com', port=443): Max retries exceeded with url: /v1/embeddings (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1032)'))).\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.langchain.com/oss/python/langchain/agents\")\n",
    "Website_docs = loader.load()\n",
    "website_Splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(Website_docs)\n",
    "os.environ[\"VOYAGE_API_KEY\"]  \n",
    "\n",
    "voyage_embeddings = VoyageEmbeddings(\n",
    "    model=\"voyage-2\",         \n",
    "    batch_size=32             \n",
    ")\n",
    "vectorstore = FAISS.from_documents(\n",
    "    website_Splitter,\n",
    "    voyage_embeddings,\n",
    ")\n",
    "vectorstore.save_local(\"faiss_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "467a085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a35382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain_agents'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "retriever = vectorstore_retriever\n",
    "\n",
    "def summarize_docs(query: str) -> str:\n",
    "    docs = retriever.invoke(query)\n",
    "    if not docs:\n",
    "        return \"No relevant context found.\"\n",
    "    chunks = [f\"Source {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs[:4])]\n",
    "    return \"\\n\\n\".join(chunks)\n",
    "\n",
    "langchain_agents_tool = Tool(\n",
    "    name=\"Langchain_agents\",\n",
    "    description=\"Answer questions about LangChain agents docs.\",\n",
    "    func=summarize_docs,\n",
    ")\n",
    "langchain_agents_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f986f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A website where all the research papers are published is arxiv. We can use arxiv API to fetch the research papers and create a tool for it. \n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun \n",
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k=2, doc_content_chars_max=300)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f7818aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool, langchain_agents_tool, arxiv_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83fa1bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\HP\\\\.conda\\\\envs\\\\myenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=300)),\n",
       " Tool(name='Langchain_agents', description='Answer questions about LangChain agents docs.', func=<function summarize_docs at 0x0000018EEC82D120>),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=300))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e537f49",
   "metadata": {},
   "source": [
    "# AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd8b3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model = \"arcee-ai/trinity-large-preview:free\",\n",
    "    temperature = 0.9,\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8000\",\n",
    "        \"X-Title\": \"RAG with Langchain\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09f34c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant who answers questions with the help of tools. \"\n",
    "     \"You have access to the following tools:\\n{tools}\\n\"\n",
    "     \"If you still don't know the answer after using the tools, say \\\"I don't know\\\".\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9682cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=(\n",
    "        \"You are a helpful assistant. Use the provided tools when needed. \"\n",
    "        \"If the tools cannot answer, reply with \\\"I don't know\\\".\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74d17e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what are langchin agents', additional_kwargs={}, response_metadata={}, id='98ba1500-7fcf-45c6-af80-91c455a41470'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 342, 'total_tokens': 369, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'arcee-ai/trinity-large-preview:free', 'system_fingerprint': None, 'id': 'gen-1770578612-P3Mu8Euzsu5U7Ccmf4kx', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c3eb5-5d4b-7883-9f98-16b8dc5ecdfc-0', tool_calls=[{'name': 'Langchain_agents', 'args': {'__arg1': 'what are langchain agents'}, 'id': 'call-14963c8d-09fc-4453-bb67-f7122bf4f8a6', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 342, 'output_tokens': 27, 'total_tokens': 369, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Source 1:\\nAgents - Docs by LangChainSkip to main contentDocs by LangChain home pageOpen sourceSearch...⌘KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationCore componentsAgentsDeep AgentsLangChainLangGraphIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewPrebuilt middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this pageCore componentsModelStatic modelDynamic modelToolsDefining toolsTool error handlingTool use in the ReAct loopDynamic toolsSystem promptDynamic system promptInvocationAdvanced conceptsStructured outputToolStrategyProviderStrategyMemoryDefining state via middlewareDefining state via state_schemaStreamingMiddlewareCore\\n\\nSource 2:\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoPhilosophyPreviousModelsNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyHomeAboutCareersBloggithubxlinkedinyoutubePowered by\\n\\nSource 3:\\ncreate_agent builds a graph-based agent runtime using LangGraph. A graph consists of nodes (steps) and edges (connections) that define how your agent processes information. The agent moves through this graph, executing nodes like the model node (which calls the model), the tools node (which executes tools), or middleware.Learn more about the Graph API.\\n\\u200bCore components\\n\\u200bModel\\nThe model is the reasoning engine of your agent. It can be specified in multiple ways, supporting both static and dynamic model selection.\\n\\u200bStatic model\\nStatic models are configured once when creating the agent and remain unchanged throughout execution. This is the most common and straightforward approach.\\nTo initialize a static model from a model identifier string:\\nCopyfrom langchain.agents import create_agent\\n\\nagent = create_agent(\"openai:gpt-5\", tools=tools)\\n\\nSource 4:\\nagent = create_agent(\"openai:gpt-5\", tools=tools)\\n\\nModel identifier strings support automatic inference (e.g., \"gpt-5\" will be inferred as \"openai:gpt-5\"). Refer to the reference to see a full list of model identifier string mappings.\\nFor more control over the model configuration, initialize a model instance directly using the provider package. In this example, we use ChatOpenAI. See Chat models for other available chat model classes.\\nCopyfrom langchain.agents import create_agent\\nfrom langchain_openai import ChatOpenAI\\n\\nmodel = ChatOpenAI(\\n    model=\"gpt-5\",\\n    temperature=0.1,\\n    max_tokens=1000,\\n    timeout=30\\n    # ... (other params)\\n)\\nagent = create_agent(model, tools=tools)', name='Langchain_agents', id='efb5ac67-022a-4ce2-905e-32a9636f12a5', tool_call_id='call-14963c8d-09fc-4453-bb67-f7122bf4f8a6'), AIMessage(content='LangChain agents are components that allow language models to interact with external tools and APIs to accomplish tasks. They provide a framework for creating intelligent agents that can use various tools, handle tool errors, and employ different strategies for tool use. LangChain agents support both static and dynamic model selection, and can be configured to use different types of tools and memory systems. They are designed to enhance the capabilities of language models by enabling them to access and utilize external information and services.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 973, 'total_tokens': 1067, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'arcee-ai/trinity-large-preview:free', 'system_fingerprint': None, 'id': 'gen-1770578619-iI9Dp5GkWUxeU6ttXKvW', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3eb5-9a89-7be1-9e93-db0601747876-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 973, 'output_tokens': 94, 'total_tokens': 1067, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "Query = input(\"Enter your Query\")\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": Query}]}\n",
    "result = agent.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27fbcdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain agents are components that allow language models to interact with external tools and APIs to accomplish tasks. They provide a framework for creating intelligent agents that can use various tools, handle tool errors, and employ different strategies for tool use. LangChain agents support both static and dynamic model selection, and can be configured to use different types of tools and memory systems. They are designed to enhance the capabilities of language models by enabling them to access and utilize external information and services.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
